#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤©æ°£è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥å·¥å…·
åŠŸèƒ½ï¼š
1. æª¢æŸ¥æ¯å€‹æ—¥æœŸæ˜¯å¦éƒ½æœ‰16å€‹ç¸£å¸‚çš„å¤©æ°£è³‡æ–™
2. è­˜åˆ¥ç¼ºå¤±çš„ç¸£å¸‚è³‡æ–™
3. ç”Ÿæˆè©³ç´°çš„å®Œæ•´æ€§å ±å‘Š
4. çµ±è¨ˆè³‡æ–™è¦†è“‹ç‡
"""

import sys
import io
import os
import pandas as pd
from sqlalchemy import create_engine
from datetime import datetime, timedelta
from collections import defaultdict

# è¨­å®šæ¨™æº–è¼¸å‡ºç·¨ç¢¼ç‚ºUTF-8ï¼Œè§£æ±ºWindows cp950ç·¨ç¢¼å•é¡Œ
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    os.environ['PYTHONIOENCODING'] = 'utf-8'

class WeatherDataCompletenessChecker:
    """å¤©æ°£è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥å™¨"""
    
    def __init__(self, connection_string="postgresql+psycopg2://lorraine:0000@111.184.52.4:9527/postgres"):
        """åˆå§‹åŒ–"""
        self.connection_string = connection_string
        self.table_name = "weather_data"
        self.engine = None
        
        # å®šç¾©å®Œæ•´çš„16å€‹ç¸£å¸‚åˆ—è¡¨
        self.expected_cities = {
            'NTO', 'CYQ', 'ILN', 'PIF', 'CHA', 'NTP', 'HSC', 'TAO', 
            'TXG', 'TPE', 'TNN', 'TTT', 'HUA', 'MIA', 'YUN', 'KHH'
        }
        
        # ç¸£å¸‚ä»£ç¢¼åˆ°åç¨±çš„å°æ‡‰
        self.city_names = {
            'NTO': 'å—æŠ•ç¸£', 'CYQ': 'å˜‰ç¾©ç¸£', 'ILN': 'å®œè˜­ç¸£', 'PIF': 'å±æ±ç¸£',
            'CHA': 'å½°åŒ–ç¸£', 'NTP': 'æ–°åŒ—å¸‚', 'HSC': 'æ–°ç«¹ç¸£', 'TAO': 'æ¡ƒåœ’å¸‚',
            'TXG': 'è‡ºä¸­å¸‚', 'TPE': 'è‡ºåŒ—å¸‚', 'TNN': 'è‡ºå—å¸‚', 'TTT': 'è‡ºæ±ç¸£',
            'HUA': 'èŠ±è“®ç¸£', 'MIA': 'è‹—æ —ç¸£', 'YUN': 'é›²æ—ç¸£', 'KHH': 'é«˜é›„å¸‚'
        }

        # åƒ¹æ ¼è³‡æ–™è¨­å®š
        self.price_table = "daily_avg_price"
        self.price_expected_count = 48  # æ¯æ—¥æ‡‰æœ‰ 48 ç¨®è”¬èœ
        self.price_date_candidates = ["ObsTime", "date", "obs_date", "Date", "obs_time"]
        self.price_id_candidates = ["vege_id", "id", "vegetable_id"]
        
    def connect_database(self):
        """é€£æ¥è³‡æ–™åº«"""
        try:
            print("[é€£æ¥] æ­£åœ¨é€£æ¥è³‡æ–™åº«...")
            self.engine = create_engine(self.connection_string)
            # æ¸¬è©¦é€£æ¥
            with self.engine.connect() as conn:
                from sqlalchemy import text
                conn.execute(text("SELECT 1"))
            print("[æˆåŠŸ] è³‡æ–™åº«é€£æ¥æˆåŠŸ")
            return True
        except Exception as e:
            print(f"[éŒ¯èª¤] è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
            return False
    
    def get_date_range(self):
        """ç²å–è³‡æ–™åº«ä¸­çš„æ—¥æœŸç¯„åœ"""
        try:
            query = f'''
            SELECT 
                MIN("ObsTime") as min_date,
                MAX("ObsTime") as max_date,
                COUNT(DISTINCT "ObsTime") as total_dates
            FROM "{self.table_name}"
            '''
            
            result = pd.read_sql(query, self.engine)
            min_date = result['min_date'].iloc[0]
            max_date = result['max_date'].iloc[0]
            total_dates = result['total_dates'].iloc[0]
            
            print(f"[ç¯„åœ] è³‡æ–™æ—¥æœŸç¯„åœ: {min_date} ~ {max_date}")
            print(f"[çµ±è¨ˆ] ç¸½å…±æœ‰ {total_dates} å€‹ä¸åŒæ—¥æœŸçš„è³‡æ–™")
            
            return min_date, max_date, total_dates
            
        except Exception as e:
            print(f"[éŒ¯èª¤] ç²å–æ—¥æœŸç¯„åœå¤±æ•—: {e}")
            return None, None, 0
    
    def check_daily_completeness(self):
        """æª¢æŸ¥æ¯æ—¥è³‡æ–™å®Œæ•´æ€§"""
        print(f"\n[æª¢æŸ¥] æ­£åœ¨æª¢æŸ¥æ¯æ—¥è³‡æ–™å®Œæ•´æ€§...")
        
        try:
            # æŸ¥è©¢æ¯å€‹æ—¥æœŸçš„ç¸£å¸‚è³‡æ–™æ•¸é‡
            query = f'''
            SELECT 
                "ObsTime",
                COUNT(*) as city_count,
                STRING_AGG(city_id, ', ' ORDER BY city_id) as cities
            FROM "{self.table_name}"
            GROUP BY "ObsTime"
            ORDER BY "ObsTime"
            '''
            
            daily_data = pd.read_sql(query, self.engine)
            
            print(f"[è³‡æ–™] å…±æŸ¥è©¢åˆ° {len(daily_data)} å€‹æ—¥æœŸçš„è³‡æ–™")
            
            # åˆ†æå®Œæ•´æ€§
            complete_dates = []
            incomplete_dates = []
            missing_cities_summary = defaultdict(int)
            
            for _, row in daily_data.iterrows():
                obs_time = row['ObsTime']
                city_count = row['city_count']
                cities = set(row['cities'].split(', ')) if row['cities'] else set()
                
                if city_count == 16:
                    complete_dates.append(obs_time)
                else:
                    missing_cities = self.expected_cities - cities
                    incomplete_dates.append({
                        'date': obs_time,
                        'city_count': city_count,
                        'cities': cities,
                        'missing_cities': missing_cities
                    })
                    
                    # çµ±è¨ˆæ¯å€‹åŸå¸‚çš„ç¼ºå¤±æ¬¡æ•¸
                    for city in missing_cities:
                        missing_cities_summary[city] += 1
            
            return daily_data, complete_dates, incomplete_dates, missing_cities_summary
            
        except Exception as e:
            print(f"[éŒ¯èª¤] æª¢æŸ¥æ—¥æœŸå®Œæ•´æ€§å¤±æ•—: {e}")
            return None, [], [], {}
    
    def generate_report(self, daily_data, complete_dates, incomplete_dates, missing_cities_summary):
        """ç”Ÿæˆè©³ç´°å ±å‘Š"""
        print(f"\n" + "=" * 80)
        print("å¤©æ°£è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥å ±å‘Š")
        print("=" * 80)
        print(f"æª¢æŸ¥æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        total_dates = len(daily_data)
        complete_count = len(complete_dates)
        incomplete_count = len(incomplete_dates)
        completeness_rate = (complete_count / total_dates * 100) if total_dates > 0 else 0
        
        print(f"\nğŸ“Š ç¸½é«”çµ±è¨ˆ:")
        print(f"   ç¸½æ—¥æœŸæ•¸: {total_dates}")
        print(f"   å®Œæ•´æ—¥æœŸæ•¸: {complete_count} (16ç¸£å¸‚)")
        print(f"   ä¸å®Œæ•´æ—¥æœŸæ•¸: {incomplete_count}")
        print(f"   å®Œæ•´ç‡: {completeness_rate:.2f}%")
        
        if incomplete_dates:
            print(f"\nâš ï¸  ä¸å®Œæ•´æ—¥æœŸè©³æƒ…:")
            print("=" * 80)
            print(f"{'æ—¥æœŸ':<12} {'ç¸£å¸‚æ•¸':<6} {'ç¼ºå¤±ç¸£å¸‚':<20} {'ç¼ºå¤±ç¸£å¸‚åç¨±'}")
            print("=" * 80)
            
            for item in incomplete_dates:
                date_str = str(item['date'])[:10]
                missing_cities_str = ', '.join(sorted(item['missing_cities']))
                missing_names = ', '.join([self.city_names[city] for city in sorted(item['missing_cities'])])
                print(f"{date_str:<12} {item['city_count']:<6} {missing_cities_str:<20} {missing_names}")
            
            print("=" * 80)
            
            # çµ±è¨ˆæœ€å¸¸ç¼ºå¤±çš„ç¸£å¸‚
            if missing_cities_summary:
                print(f"\nğŸ“ˆ ç¸£å¸‚ç¼ºå¤±çµ±è¨ˆ:")
                print("=" * 50)
                print(f"{'ç¸£å¸‚ä»£ç¢¼':<8} {'ç¸£å¸‚åç¨±':<10} {'ç¼ºå¤±æ¬¡æ•¸':<8} {'ç¼ºå¤±ç‡'}")
                print("=" * 50)
                
                for city, count in sorted(missing_cities_summary.items(), key=lambda x: x[1], reverse=True):
                    missing_rate = (count / total_dates * 100) if total_dates > 0 else 0
                    city_name = self.city_names.get(city, 'æœªçŸ¥')
                    print(f"{city:<8} {city_name:<10} {count:<8} {missing_rate:.1f}%")
                
                print("=" * 50)
        
        # é¡¯ç¤ºæœ€è¿‘çš„æ—¥æœŸç‹€æ³
        print(f"\nğŸ“… æœ€è¿‘æ—¥æœŸç‹€æ³ (æœ€æ–°10å¤©):")
        print("=" * 60)
        print(f"{'æ—¥æœŸ':<12} {'ç¸£å¸‚æ•¸':<6} {'ç‹€æ…‹':<10} {'ç¼ºå¤±ç¸£å¸‚'}")
        print("=" * 60)
        
        recent_data = daily_data.tail(10)
        for _, row in recent_data.iterrows():
            date_str = str(row['ObsTime'])[:10]
            city_count = row['city_count']
            status = "âœ… å®Œæ•´" if city_count == 16 else f"âŒ ä¸å®Œæ•´"
            
            if city_count == 16:
                missing_str = "-"
            else:
                cities = set(row['cities'].split(', ')) if row['cities'] else set()
                missing_cities = self.expected_cities - cities
                missing_str = ', '.join(sorted(missing_cities))
            
            print(f"{date_str:<12} {city_count:<6} {status:<10} {missing_str}")
        
        print("=" * 60)
    
    def check_specific_date_range(self, start_date=None, end_date=None):
        """æª¢æŸ¥ç‰¹å®šæ—¥æœŸç¯„åœ"""
        if start_date and end_date:
            print(f"\n[ç‰¹å®šç¯„åœ] æª¢æŸ¥ {start_date} åˆ° {end_date} çš„è³‡æ–™...")
            
            query = f'''
            SELECT 
                "ObsTime",
                COUNT(*) as city_count,
                STRING_AGG(city_id, ', ' ORDER BY city_id) as cities
            FROM "{self.table_name}"
            WHERE "ObsTime" >= %(start_date)s AND "ObsTime" <= %(end_date)s
            GROUP BY "ObsTime"
            ORDER BY "ObsTime"
            '''
            
            try:
                range_data = pd.read_sql(query, self.engine, params={
                    'start_date': start_date,
                    'end_date': end_date
                })
                
                print(f"[çµæœ] æŒ‡å®šç¯„åœå…§å…±æœ‰ {len(range_data)} å€‹æ—¥æœŸ")
                
                for _, row in range_data.iterrows():
                    date_str = str(row['ObsTime'])[:10]
                    city_count = row['city_count']
                    
                    if city_count == 16:
                        print(f"  {date_str}: âœ… å®Œæ•´ ({city_count}/16)")
                    else:
                        cities = set(row['cities'].split(', ')) if row['cities'] else set()
                        missing_cities = self.expected_cities - cities
                        missing_str = ', '.join(sorted(missing_cities))
                        print(f"  {date_str}: âŒ ä¸å®Œæ•´ ({city_count}/16) ç¼ºå¤±: {missing_str}")
                
            except Exception as e:
                print(f"[éŒ¯èª¤] æŸ¥è©¢ç‰¹å®šç¯„åœå¤±æ•—: {e}")
    
    def suggest_fixes(self, incomplete_dates):
        """å»ºè­°ä¿®å¾©æ–¹æ¡ˆ"""
        if not incomplete_dates:
            return
            
        print(f"\nğŸ”§ ä¿®å¾©å»ºè­°:")
        print("=" * 50)
        
        # åˆ†æç¼ºå¤±æ¨¡å¼
        pattern_analysis = {}
        for item in incomplete_dates:
            missing_tuple = tuple(sorted(item['missing_cities']))
            if missing_tuple not in pattern_analysis:
                pattern_analysis[missing_tuple] = []
            pattern_analysis[missing_tuple].append(item['date'])
        
        print(f"ç™¼ç¾ {len(pattern_analysis)} ç¨®ä¸åŒçš„ç¼ºå¤±æ¨¡å¼:")
        
        for i, (missing_cities, dates) in enumerate(pattern_analysis.items(), 1):
            missing_names = ', '.join([self.city_names[city] for city in missing_cities])
            print(f"\næ¨¡å¼ {i}: ç¼ºå¤± {missing_names} ({len(missing_cities)}å€‹ç¸£å¸‚)")
            print(f"  å½±éŸ¿æ—¥æœŸæ•¸: {len(dates)}")
            print(f"  æ—¥æœŸç¯„åœ: {min(dates)} ~ {max(dates)}")
            
            if len(dates) <= 5:
                print(f"  å…·é«”æ—¥æœŸ: {', '.join([str(d)[:10] for d in dates])}")
        
        print(f"\nå»ºè­°:")
        print(f"1. æª¢æŸ¥å¤©æ°£è³‡æ–™æ”¶é›†ç¨‹å¼æ˜¯å¦æ­£å¸¸é‹è¡Œ")
        print(f"2. ç¢ºèªAPIå›æ‡‰æ˜¯å¦åŒ…å«æ‰€æœ‰ç¸£å¸‚è³‡æ–™")
        print(f"3. æª¢æŸ¥è³‡æ–™åº«å¯«å…¥é‚è¼¯æ˜¯å¦æœ‰éŒ¯èª¤")
        print(f"4. å°æ–¼æ­·å²ç¼ºå¤±è³‡æ–™ï¼Œå¯è€ƒæ…®é‡æ–°åŸ·è¡Œå°æ‡‰æ—¥æœŸçš„è³‡æ–™æ”¶é›†")
    
    def close_connection(self):
        """é—œé–‰è³‡æ–™åº«é€£æ¥"""
        if self.engine:
            self.engine.dispose()
            print("[é—œé–‰] è³‡æ–™åº«é€£æ¥å·²é—œé–‰")

    # ===================== æ–°å¢ï¼šåƒ¹æ ¼å®Œæ•´æ€§æª¢æŸ¥ =====================
    def _detect_column(self, table: str, candidates):
        """å¾è³‡æ–™è¡¨æ¬„ä½ä¸­å°‹æ‰¾ç¬¬ä¸€å€‹å­˜åœ¨çš„å€™é¸æ¬„ä½å"""
        from sqlalchemy import text
        try:
            sql = text(
                """
                SELECT column_name
                FROM information_schema.columns
                WHERE table_name = :tbl
                """
            )
            df = pd.read_sql(sql, self.engine, params={"tbl": table})
            cols = set(df["column_name"].tolist())
            for c in candidates:
                if c in cols:
                    return c
        except Exception as e:
            print(f"[è­¦å‘Š] åµæ¸¬ {table} æ¬„ä½å¤±æ•—ï¼š{e}")
        return None

    def check_price_completeness(self, start_date: str, end_date: str):
        """æª¢æŸ¥ daily_avg_price åœ¨æŒ‡å®šæ—¥æœŸå€é–“çš„æ¯æ—¥ç­†æ•¸æ˜¯å¦é”åˆ° 48ï¼Œä¸¦è¼¸å‡ºåˆ†çµ„ TXT å ±å‘Šã€‚"""
        print("\n[æª¢æŸ¥] æ­£åœ¨æª¢æŸ¥åƒ¹æ ¼è³‡æ–™å®Œæ•´æ€§ (daily_avg_price)...")

        # åµæ¸¬æ—¥æœŸèˆ‡è”¬èœIDæ¬„ä½
        date_col = self._detect_column(self.price_table, self.price_date_candidates)
        id_col = self._detect_column(self.price_table, self.price_id_candidates)

        if not date_col or not id_col:
            print(f"[éŒ¯èª¤] ç„¡æ³•åµæ¸¬ {self.price_table} çš„æ—¥æœŸæˆ–è”¬èœIDæ¬„ä½ï¼Œè«‹ç¢ºèªè³‡æ–™è¡¨ schemaã€‚")
            return False

        print(f"[åµæ¸¬] ä½¿ç”¨æ—¥æœŸæ¬„ä½ï¼š{date_col}ï¼Œè”¬èœIDæ¬„ä½ï¼š{id_col}")

        # æŸ¥è©¢å€é–“å…§å„æ—¥æœŸçš„è”¬èœç­†æ•¸
        try:
            # å°è³‡æ–™è¡¨èˆ‡æ¬„ä½åŠ ä¸Šé›™å¼•è™Ÿï¼Œé¿å…å¤§å°å¯«/ä¿ç•™å­—å•é¡Œ
            query = (
                "SELECT CAST(\"{dc}\" AS DATE) AS dt, "
                "COUNT(DISTINCT \"{ic}\") AS cnt "
                "FROM \"{tbl}\" "
                "WHERE CAST(\"{dc}\" AS DATE) BETWEEN %(start)s AND %(end)s "
                "GROUP BY CAST(\"{dc}\" AS DATE) "
                "ORDER BY dt"
            ).format(dc=date_col, ic=id_col, tbl=self.price_table)
            df = pd.read_sql(query, self.engine, params={"start": start_date, "end": end_date})
            # æ­£è¦åŒ– dt æ¬„ä½ç‚º date ç‰©ä»¶
            if not df.empty:
                try:
                    df["dt"] = pd.to_datetime(df["dt"]).dt.date
                except Exception:
                    pass
        except Exception as e:
            print(f"[éŒ¯èª¤] æŸ¥è©¢åƒ¹æ ¼è³‡æ–™å¤±æ•—ï¼š{e}")
            return False

        # ç”Ÿæˆå®Œæ•´æ—¥æœŸåˆ—è¡¨ï¼Œè£œé½Šç¼ºæ¼æ—¥æœŸï¼ˆè¦–ç‚º 0 ç­†ï¼‰
        try:
            sdt = datetime.strptime(start_date, "%Y-%m-%d").date()
            edt = datetime.strptime(end_date, "%Y-%m-%d").date()
        except ValueError:
            print("[éŒ¯èª¤] æ—¥æœŸæ ¼å¼éœ€ç‚º YYYY-MM-DD")
            return False

        all_dates = []
        cur = sdt
        while cur <= edt:
            all_dates.append(cur)
            cur += timedelta(days=1)

        cnt_map = {row.dt if not hasattr(row.dt, 'date') else row.dt: int(row.cnt) for _, row in df.iterrows()}
        grouped = {}
        for d in all_dates:
            c = cnt_map.get(d, 0)
            grouped.setdefault(c, []).append(d)

        # è¼¸å‡º TXT å ±å‘Š
        folder = os.path.dirname(os.path.abspath(__file__))
        out_path = os.path.join(folder, f"åƒ¹æ ¼è³‡æ–™å®Œæ•´æ€§_{start_date}_{end_date}.txt")

        try:
            with open(out_path, "w", encoding="utf-8") as f:
                f.write(f"åƒ¹æ ¼è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥å ±å‘Šï¼ˆ{start_date} ~ {end_date}ï¼‰\n")
                f.write("=" * 60 + "\n\n")

                # å…ˆå¯« 48 ç­†é½Šå…¨ï¼Œå†å¯«å…¶ä»–åˆ†çµ„ï¼ˆç”±é«˜åˆ°ä½ï¼‰
                full_days = grouped.get(self.price_expected_count, [])
                f.write(f"{self.price_expected_count}ç­†é½Šå…¨è³‡æ–™: {len(full_days)}å¤©\n\n")

                for cnt in sorted([k for k in grouped.keys() if k != self.price_expected_count], reverse=True):
                    dates = grouped[cnt]
                    if not dates:
                        continue
                    # æ—¥æœŸåˆ—è¡¨
                    dates_str = ", ".join([d.strftime("%Y-%m-%d") for d in dates])
                    f.write(f"{cnt}ç­†è³‡æ–™: {dates_str}\n\n")

            print(f"[å®Œæˆ] å·²è¼¸å‡ºåƒ¹æ ¼å®Œæ•´æ€§å ±å‘Šï¼š{out_path}")
            # åŒæ™‚å°å‡ºæ‘˜è¦åˆ° console
            print(f"{self.price_expected_count}ç­†é½Šå…¨è³‡æ–™: {len(full_days)}å¤©")
            for cnt in sorted([k for k in grouped.keys() if k != self.price_expected_count], reverse=True):
                print(f"{cnt}ç­†è³‡æ–™: {len(grouped[cnt])}å¤©")
            return True
        except Exception as e:
            print(f"[éŒ¯èª¤] è¼¸å‡ºå ±å‘Šå¤±æ•—ï¼š{e}")
            return False

def main():
    """ä¸»ç¨‹å¼"""
    print("=" * 80)
    print("å¤©æ°£è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥å·¥å…·")
    print("=" * 80)
    
    # å‰µå»ºæª¢æŸ¥å™¨
    checker = WeatherDataCompletenessChecker()
    
    try:
        # é€£æ¥è³‡æ–™åº«
        if not checker.connect_database():
            return 1
        
        # ç²å–æ—¥æœŸç¯„åœ
        min_date, max_date, total_dates = checker.get_date_range()
        if total_dates == 0:
            print("[è­¦å‘Š] è³‡æ–™åº«ä¸­æ²’æœ‰å¤©æ°£è³‡æ–™")
            return 1
        
        # æª¢æŸ¥æ¯æ—¥å®Œæ•´æ€§
        daily_data, complete_dates, incomplete_dates, missing_cities_summary = checker.check_daily_completeness()
        
        if daily_data is None:
            return 1
        
        # ç”Ÿæˆå ±å‘Š
        checker.generate_report(daily_data, complete_dates, incomplete_dates, missing_cities_summary)
        
        # æä¾›ä¿®å¾©å»ºè­°ï¼ˆå¤©æ°£è³‡æ–™ï¼‰
        checker.suggest_fixes(incomplete_dates)

        # æ–°å¢ï¼šåŸ·è¡Œåƒ¹æ ¼è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥ï¼ˆå›ºå®šç¯„åœï¼š2022-01-01 ~ 2025-08-13ï¼‰
        print("\n" + "=" * 80)
        print("åƒ¹æ ¼è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥ï¼ˆdaily_avg_priceï¼‰")
        print("=" * 80)
        checker.check_price_completeness("2022-01-01", "2025-08-13")
        
        # è©¢å•æ˜¯å¦è¦æª¢æŸ¥ç‰¹å®šæ—¥æœŸç¯„åœï¼ˆåƒ…åœ¨äº’å‹•å¼çµ‚ç«¯åŸ·è¡Œï¼‰
        if sys.stdin.isatty():
            print(f"\n" + "=" * 80)
            while True:
                check_range = input("\næ˜¯å¦è¦æª¢æŸ¥ç‰¹å®šæ—¥æœŸç¯„åœ? (y/n): ").strip().lower()
                if check_range in ['n', 'no']:
                    break
                elif check_range in ['y', 'yes']:
                    try:
                        start_input = input("è«‹è¼¸å…¥é–‹å§‹æ—¥æœŸ (YYYY-MM-DD): ").strip()
                        end_input = input("è«‹è¼¸å…¥çµæŸæ—¥æœŸ (YYYY-MM-DD): ").strip()
                        
                        # é©—è­‰æ—¥æœŸæ ¼å¼
                        start_date = datetime.strptime(start_input, '%Y-%m-%d').date()
                        end_date = datetime.strptime(end_input, '%Y-%m-%d').date()
                        
                        checker.check_specific_date_range(start_date, end_date)
                        break
                        
                    except ValueError:
                        print("[éŒ¯èª¤] æ—¥æœŸæ ¼å¼ä¸æ­£ç¢ºï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
                    except Exception as e:
                        print(f"[éŒ¯èª¤] æª¢æŸ¥ç‰¹å®šç¯„åœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        break
                else:
                    print("è«‹è¼¸å…¥ y æˆ– n")
        else:
            print("\n[ç•¥é] éäº’å‹•ç’°å¢ƒï¼Œè·³éç‰¹å®šæ—¥æœŸç¯„åœè©¢å•ã€‚")
    
    except KeyboardInterrupt:
        print("\n[ä¸­æ–·] ç¨‹å¼è¢«ç”¨æˆ¶ä¸­æ–·")
        return 1
    except Exception as e:
        print(f"[éŒ¯èª¤] ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}")
        return 1
    finally:
        checker.close_connection()
    
    print("\n" + "=" * 80)
    print("æª¢æŸ¥å®Œæˆï¼")
    print("=" * 80)
    return 0

if __name__ == "__main__":
    exit(main())